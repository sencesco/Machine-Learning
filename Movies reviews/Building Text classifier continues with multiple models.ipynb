{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset: https://www.kaggle.com/nltkdata/movie-review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the library "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('movie_review.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold_id</th>\n",
       "      <th>cv_tag</th>\n",
       "      <th>html_id</th>\n",
       "      <th>sent_id</th>\n",
       "      <th>text</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>cv000</td>\n",
       "      <td>29590</td>\n",
       "      <td>0</td>\n",
       "      <td>films adapted from comic books have had plenty...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>cv000</td>\n",
       "      <td>29590</td>\n",
       "      <td>1</td>\n",
       "      <td>for starters , it was created by alan moore ( ...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>cv000</td>\n",
       "      <td>29590</td>\n",
       "      <td>2</td>\n",
       "      <td>to say moore and campbell thoroughly researche...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>cv000</td>\n",
       "      <td>29590</td>\n",
       "      <td>3</td>\n",
       "      <td>the book ( or \" graphic novel , \" if you will ...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>cv000</td>\n",
       "      <td>29590</td>\n",
       "      <td>4</td>\n",
       "      <td>in other words , don't dismiss this film becau...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fold_id cv_tag  html_id  sent_id  \\\n",
       "0        0  cv000    29590        0   \n",
       "1        0  cv000    29590        1   \n",
       "2        0  cv000    29590        2   \n",
       "3        0  cv000    29590        3   \n",
       "4        0  cv000    29590        4   \n",
       "\n",
       "                                                text  tag  \n",
       "0  films adapted from comic books have had plenty...  pos  \n",
       "1  for starters , it was created by alan moore ( ...  pos  \n",
       "2  to say moore and campbell thoroughly researche...  pos  \n",
       "3  the book ( or \" graphic novel , \" if you will ...  pos  \n",
       "4  in other words , don't dismiss this film becau...  pos  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:,-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        films adapted from comic books have had plenty...\n",
       "1        for starters , it was created by alan moore ( ...\n",
       "2        to say moore and campbell thoroughly researche...\n",
       "3        the book ( or \" graphic novel , \" if you will ...\n",
       "4        in other words , don't dismiss this film becau...\n",
       "                               ...                        \n",
       "64715    that lack of inspiration can be traced back to...\n",
       "64716    like too many of the skits on the current inca...\n",
       "64717    after watching one of the \" roxbury \" skits on...\n",
       "64718     bump unsuspecting women , and . . . that's all .\n",
       "64719    after watching _a_night_at_the_roxbury_ , you'...\n",
       "Name: text, Length: 64720, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "# corpus = ['This is the first document.',\n",
    "#             'This document is the second document.',\n",
    "#             'And this is the third one.',\n",
    "#             'Is this the first document?']\n",
    "# vectorizer = CountVectorizer()\n",
    "# X = vectorizer.fit_transform(corpus)\n",
    "# print(vectorizer.get_feature_names())\n",
    "# print(X.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TfidfVectorizer documentation \n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working With Text Data tutorial \n",
    "https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# corpus = ['This is the first document.',\n",
    "#             'This document is the second document.',\n",
    "#             'And this is the third one.',\n",
    "#             'Is this the first document?']\n",
    "\n",
    "# vectorizer = TfidfVectorizer()\n",
    "# X = vectorizer.fit_transform(corpus)\n",
    "# print(vectorizer.get_feature_names())\n",
    "\n",
    "# print(X.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LinearSVC model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6983158220024722\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "text_clf = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', LinearSVC()),\n",
    "])\n",
    "text_clf.fit(X_train, y_train)\n",
    "y_pred = text_clf.predict(X_test)\n",
    "print(accuracy_score(y_pred,y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.69      0.69      0.69      6336\n",
      "         pos       0.70      0.71      0.71      6608\n",
      "\n",
      "    accuracy                           0.70     12944\n",
      "   macro avg       0.70      0.70      0.70     12944\n",
      "weighted avg       0.70      0.70      0.70     12944\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4343 1993]\n",
      " [1912 4696]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive bayes model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7074320148331273\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "text_clf = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', MultinomialNB()),\n",
    "])\n",
    "text_clf.fit(X_train, y_train)\n",
    "y_pred = text_clf.predict(X_test)\n",
    "print(accuracy_score(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.68      0.70      0.69      6080\n",
      "         pos       0.73      0.71      0.72      6864\n",
      "\n",
      "    accuracy                           0.71     12944\n",
      "   macro avg       0.71      0.71      0.71     12944\n",
      "weighted avg       0.71      0.71      0.71     12944\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4274 1806]\n",
      " [1981 4883]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5089616810877626\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "text_clf = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', KNeighborsClassifier()),\n",
    "])\n",
    "text_clf.fit(X_train, y_train)\n",
    "y_pred = text_clf.predict(X_test)\n",
    "print(accuracy_score(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.63      0.49      0.56      8035\n",
      "         pos       0.39      0.53      0.45      4909\n",
      "\n",
      "    accuracy                           0.51     12944\n",
      "   macro avg       0.51      0.51      0.50     12944\n",
      "weighted avg       0.54      0.51      0.52     12944\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3967 4068]\n",
      " [2288 2621]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:22:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0.6269313967861557\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "text_clf = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', xgb.XGBClassifier()),\n",
    "])\n",
    "text_clf.fit(X_train, y_train)\n",
    "y_pred = text_clf.predict(X_test)\n",
    "print(accuracy_score(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.59      0.62      0.61      6016\n",
      "         pos       0.66      0.63      0.65      6928\n",
      "\n",
      "    accuracy                           0.63     12944\n",
      "   macro avg       0.63      0.63      0.63     12944\n",
      "weighted avg       0.63      0.63      0.63     12944\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3721 2295]\n",
      " [2534 4394]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6355840543881335\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "text_clf = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', RandomForestClassifier()),\n",
    "])\n",
    "text_clf.fit(X_train, y_train)\n",
    "y_pred = text_clf.predict(X_test)\n",
    "print(accuracy_score(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.58      0.63      0.61      5774\n",
      "         pos       0.68      0.64      0.66      7170\n",
      "\n",
      "    accuracy                           0.64     12944\n",
      "   macro avg       0.63      0.64      0.63     12944\n",
      "weighted avg       0.64      0.64      0.64     12944\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3656 2118]\n",
      " [2599 4571]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
