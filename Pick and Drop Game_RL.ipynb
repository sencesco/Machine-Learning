{"cells":[{"cell_type":"markdown","source":["## Setting up the game field and rules"],"metadata":{"id":"ghic9-AdgmoY"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"Dp9GJ4xSIhNj","executionInfo":{"status":"ok","timestamp":1705658409994,"user_tz":-420,"elapsed":618,"user":{"displayName":"Somchai Kradingthong","userId":"06050472122727612979"}}},"outputs":[],"source":["class Field:\n","    def __init__(self, size, item_pickup, item_dropoff, start_position):\n","        self.size = size  # size of the borad or field\n","        self.item_pickup = item_pickup\n","        self.item_dropoff = item_dropoff\n","        self.position = start_position\n","        self.item_in_car = False\n","\n","    def get_number_of_states(self):\n","        # All possible state\n","        # We have m row * n column\n","\n","        # So posibility of picked-up = m*n\n","        # Meanwhile posibility of drop-off = m*n\n","        # And last check the agent have carry item or not = *2\n","        return self.size*self.size*self.size*self.size*2\n","\n","    def get_state(self):\n","        # One to one mapping wiht Q-table\n","        # position[0] = x\n","        # position[1] = y\n","        state = self.position[0]*self.size*self.size*self.size*2\n","        state = state + self.position[1]*self.size*self.size*2\n","        state = state + self.item_pickup[0]*self.size*2\n","        state = state + self.item_pickup[1]*2\n","\n","        if self.item_in_car:\n","            state = state + 1\n","        return state\n","\n","    # Take action and receive reward fromn the rules\n","    def make_action(self, action):\n","\n","        (x,y) = self.position\n","\n","        if action == 0: # down\n","            if y == self.size-1:\n","                return -10, False\n","            else:\n","                self.position = (x, y+1)\n","                return -1, False\n","\n","        elif action == 1: # up\n","            if y == 0:\n","                return -10, False\n","            else:\n","                self.position = (x, y-1)\n","                return -1, False\n","\n","        elif action == 2: # left\n","            if x == 0:\n","                return -10, False\n","            else:\n","                self.position = (x-1, y)\n","                return -1, False\n","\n","        elif action == 3: # right\n","            if x == self.size-1:\n","                return -10, False\n","            else:\n","                self.position = (x+1, y)\n","                return -1, False\n","\n","        elif action == 4: # pick-up\n","            if self.item_in_car:\n","                return -10, False\n","            elif self.item_pickup != (x,y):\n","                return -10, False\n","            else:\n","                self.item_in_car = True\n","                return 20, False\n","\n","        elif action == 5: # drop-off\n","            if not self.item_in_car:\n","                return -10, False\n","            elif self.item_dropoff != (x,y):\n","                self.item_pickup = (x,y)\n","                self.item_in_car = False\n","                return -10, False\n","            else:\n","                self.item_in_car = False\n","                return 20, True"]},{"cell_type":"markdown","source":["## Play a game manually"],"metadata":{"id":"r5AiESgpg8xv"}},{"cell_type":"code","execution_count":2,"metadata":{"id":"18r4SxQeIhNq","executionInfo":{"status":"ok","timestamp":1705658410840,"user_tz":-420,"elapsed":26,"user":{"displayName":"Somchai Kradingthong","userId":"06050472122727612979"}}},"outputs":[],"source":["size = 10\n","item_pickup = (0,0)\n","item_dropoff = (9,9)\n","start_position = (9,0)\n","\n","field = Field(size, item_pickup, item_dropoff, start_position)"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"tM06BAj9IhNq","outputId":"6f247e52-c81a-4c23-d7ec-b16a6987d447","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1705658410841,"user_tz":-420,"elapsed":26,"user":{"displayName":"Somchai Kradingthong","userId":"06050472122727612979"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(9, 0)"]},"metadata":{},"execution_count":3}],"source":["field.position"]},{"cell_type":"code","source":["field.make_action(2)\n","field.make_action(2)\n","field.make_action(2)\n","field.make_action(2)\n","field.make_action(2)\n","field.make_action(2)\n","field.make_action(2)\n","field.make_action(2)\n","field.make_action(2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NmcgTQQ-lU2P","executionInfo":{"status":"ok","timestamp":1705658410841,"user_tz":-420,"elapsed":24,"user":{"displayName":"Somchai Kradingthong","userId":"06050472122727612979"}},"outputId":"e67d763a-a477-4eb7-9954-e50569564a78"},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(-1, False)"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["field.make_action(4)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B8liKmkvlYRu","executionInfo":{"status":"ok","timestamp":1705658410841,"user_tz":-420,"elapsed":21,"user":{"displayName":"Somchai Kradingthong","userId":"06050472122727612979"}},"outputId":"99b0f6ad-bf73-41c2-d3bb-671572cd34cb"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(20, False)"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["field.make_action(0)\n","field.make_action(0)\n","field.make_action(0)\n","field.make_action(0)\n","field.make_action(0)\n","field.make_action(0)\n","field.make_action(0)\n","field.make_action(0)\n","field.make_action(0)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ad0p8IaKldNW","executionInfo":{"status":"ok","timestamp":1705658410841,"user_tz":-420,"elapsed":17,"user":{"displayName":"Somchai Kradingthong","userId":"06050472122727612979"}},"outputId":"c46e51f3-76a9-4033-e57b-29cf1c63cb8a"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(-1, False)"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["field.make_action(3)\n","field.make_action(3)\n","field.make_action(3)\n","field.make_action(3)\n","field.make_action(3)\n","field.make_action(3)\n","field.make_action(3)\n","field.make_action(3)\n","field.make_action(3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wi-pcCQclhE-","executionInfo":{"status":"ok","timestamp":1705658410842,"user_tz":-420,"elapsed":15,"user":{"displayName":"Somchai Kradingthong","userId":"06050472122727612979"}},"outputId":"24b0092d-e7ca-4489-9aff-4adf0f396dae"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(-1, False)"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","execution_count":8,"metadata":{"id":"0wTp7ln3IhNr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1705658410842,"user_tz":-420,"elapsed":12,"user":{"displayName":"Somchai Kradingthong","userId":"06050472122727612979"}},"outputId":"ef2fb8ee-85bb-4995-fb3b-fd9a7767c8df"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(20, True)"]},"metadata":{},"execution_count":8}],"source":["field.make_action(5)"]},{"cell_type":"markdown","source":["## Play a game auto"],"metadata":{"id":"eYX8fhKImPef"}},{"cell_type":"markdown","source":["### Random plan with Naive Random Solution"],"metadata":{"id":"YGXSGq1Jmo1c"}},{"cell_type":"code","execution_count":9,"metadata":{"id":"eAxgIrlCIhNs","executionInfo":{"status":"ok","timestamp":1705658410842,"user_tz":-420,"elapsed":10,"user":{"displayName":"Somchai Kradingthong","userId":"06050472122727612979"}}},"outputs":[],"source":["import random"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"PR-tJF4DIhNt","executionInfo":{"status":"ok","timestamp":1705658410842,"user_tz":-420,"elapsed":10,"user":{"displayName":"Somchai Kradingthong","userId":"06050472122727612979"}}},"outputs":[],"source":["# 1 episode\n","def random_solution():\n","    size = 10\n","    item_pickup = (0,0)\n","    item_dropoff = (9,9)\n","    start_position = (9,0)\n","\n","    field = Field(size, item_pickup, item_dropoff, start_position)\n","\n","    done = False\n","    steps = 0\n","\n","    while not done:\n","        action = random.randint(0,5)\n","        reward, done = field.make_action(action)\n","        steps = steps + 1\n","\n","    return steps\n"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"Q41KM07iIhNt","outputId":"f977e494-2438-463e-d7e8-c8fc665d6851","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1705658410843,"user_tz":-420,"elapsed":10,"user":{"displayName":"Somchai Kradingthong","userId":"06050472122727612979"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["31585"]},"metadata":{},"execution_count":11}],"source":["# Number of step or moving time that done\n","random_solution()"]},{"cell_type":"markdown","source":["- average runing"],"metadata":{"id":"_2ms1Jrro2Km"}},{"cell_type":"code","execution_count":12,"metadata":{"id":"Ine63KBrIhNu","executionInfo":{"status":"ok","timestamp":1705658432573,"user_tz":-420,"elapsed":21739,"user":{"displayName":"Somchai Kradingthong","userId":"06050472122727612979"}}},"outputs":[],"source":["run = [random_solution() for _ in range(100)]"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"Js_A6PSAIhNu","outputId":"6f23e4ec-df03-497d-e392-d920fe3b8ab7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1705658432574,"user_tz":-420,"elapsed":21,"user":{"displayName":"Somchai Kradingthong","userId":"06050472122727612979"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["142920.57"]},"metadata":{},"execution_count":13}],"source":["sum(run)/len(run)"]},{"cell_type":"markdown","source":["### Q-Learning algorithm plan"],"metadata":{"id":"HGqWcYfQoybg"}},{"cell_type":"code","execution_count":14,"metadata":{"id":"CUfxjq1CIhNv","executionInfo":{"status":"ok","timestamp":1705658432574,"user_tz":-420,"elapsed":5,"user":{"displayName":"Somchai Kradingthong","userId":"06050472122727612979"}}},"outputs":[],"source":["import numpy as np"]},{"cell_type":"code","source":["import numpy as np\n","#                             alpha    ,       gamma         ,          epsilon\n","def q_learning(field, learning_rate=0.1, discount_factor=0.9, exploration_rate=0.1, max_steps=1000):\n","    size = field.size\n","    num_states = field.get_number_of_states()\n","    q_table = np.zeros((num_states, 6))  # 6 possible actions\n","\n","    def select_action(state):\n","        if np.random.rand() < exploration_rate:\n","            return np.random.choice(6)  # Explore: choose a random action\n","        else:\n","            return np.argmax(q_table[state, :])  # Exploit: choose the action with the highest Q-value\n","\n","    def update_q_table(state, action, reward, next_state):\n","        best_next_action = np.argmax(q_table[next_state, :])\n","        q_table[state, action] += learning_rate * (reward + discount_factor * q_table[next_state, best_next_action] - q_table[state, action])\n","\n","    state = field.get_state()\n","    steps = 0\n","\n","    for _ in range(max_steps):\n","        action = select_action(state)\n","        reward, done = field.make_action(action)\n","\n","        steps += 1\n","\n","        next_state = field.get_state()\n","        update_q_table(state, action, reward, next_state)\n","\n","        state = next_state\n","\n","        if done:\n","            return steps\n","\n","    return max_steps  # Return max_steps if the goal is not reached within the specified maximum steps\n","\n","# Example usage:\n","size = 5\n","item_pickup = (1, 1)\n","item_dropoff = (4, 4)\n","start_position = (0, 0)\n","\n","field = Field(size, item_pickup, item_dropoff, start_position)\n","\n","# Run Q-learning for a specific number of episodes\n","num_episodes = 1\n","total_steps = 0\n","\n","for episode in range(num_episodes):\n","    steps = q_learning(field)\n","    total_steps += steps\n","\n","\n","\n","average_steps = total_steps / num_episodes\n","print(f\"Average Steps to Goal over {num_episodes} episodes: \\nTotal step {total_steps} \\nAverage  step {average_steps}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c7Q_7-gwJJls","executionInfo":{"status":"ok","timestamp":1705659197436,"user_tz":-420,"elapsed":11,"user":{"displayName":"Somchai Kradingthong","userId":"06050472122727612979"}},"outputId":"acb9f12b-3fcf-4cc6-adea-45334815a775"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["Average Steps to Goal over 1 episodes: \n","Total step 1000 \n","Average  step 1000.0\n"]}]},{"cell_type":"markdown","source":["When compared to random solution the Q-Learning with mae number of episode that equal to 1 will more efficiency."],"metadata":{"id":"SkyNwSwmNjoN"}},{"cell_type":"code","source":["num_episodes = 10\n","total_steps = 0\n","\n","for episode in range(num_episodes):\n","    steps = q_learning(field)\n","    total_steps += steps\n","\n","\n","\n","average_steps = total_steps / num_episodes\n","print(f\"Average Steps to Goal over {num_episodes} episodes: \\nTotal step {total_steps} \\nAverage  step {average_steps}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XJKLrQKEMK47","executionInfo":{"status":"ok","timestamp":1705659206080,"user_tz":-420,"elapsed":611,"user":{"displayName":"Somchai Kradingthong","userId":"06050472122727612979"}},"outputId":"b0caf17d-3bd7-47bb-c285-18d81a5c2c8a"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["Average Steps to Goal over 10 episodes: \n","Total step 8127 \n","Average  step 812.7\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"pGUjfpfqNgS6"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}