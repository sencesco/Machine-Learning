{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nN4Y8rnJZFxY"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import gym # pip intall gym\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "R0rlA-34ZFxb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae6fc679-6e94-4c38-f6d3-37d6bc0560ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "env = gym.make('FrozenLake-v1', is_slippery = False, new_step_api=True, render_mode='ansi')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4 action to perform with 1 step decision\n",
        "env.action_space"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G3fAAFyzZOCs",
        "outputId": "9924d6e9-cc8a-40fd-f357-e8df07062e2e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Discrete(4)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env.observation_space"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YtyJhmf0ZQLC",
        "outputId": "21ae46f5-86df-46da-84bd-65a5652cf712"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Discrete(16)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "RImvn8WuZFxc",
        "outputId": "aeba4417-7746-4aa3-a6a6-77ac7ed5f8d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q Table\n",
            " [[0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]]\n"
          ]
        }
      ],
      "source": [
        "action_space_size = env.action_space.n\n",
        "state_space_size = env.observation_space.n\n",
        "\n",
        "# Create initial Q table\n",
        "qtable = np.zeros((state_space_size, action_space_size))\n",
        "print(\"Q Table\\n\",qtable)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "Kd_ZcMZoZFxe"
      },
      "outputs": [],
      "source": [
        "total_episodes = 15000\n",
        "learning_rate = 0.2\n",
        "max_steps = 100\n",
        "gamma = 0.99\n",
        "\n",
        "epsilon = 1\n",
        "max_epsilon = 1\n",
        "min_epsilon = 0.01\n",
        "decay_rate = 0.001"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def converged_qtable(lst_qtables, interval=100, convergence_threshold=0.1):\n",
        "    if len(lst_qtables) < interval:\n",
        "        return False  # Not enough episodes to compare\n",
        "\n",
        "    avg_change = (lst_qtables[-1] - np.mean(lst_qtables[-interval:-1])) / interval\n",
        "\n",
        "    return True"
      ],
      "metadata": {
        "id": "VGmzWPWgCsYU"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "uqqBoxfWZFxf",
        "outputId": "5b4f37d8-70cb-4ab0-8896-5c26c8f4e162",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score: 0.9000666666666667\n",
            "lasted update of qtable: \n",
            "[[0.94148015 0.95099005 0.95099005 0.94148015]\n",
            " [0.94148015 0.         0.96059601 0.95099005]\n",
            " [0.95099005 0.970299   0.95099005 0.96059601]\n",
            " [0.96059601 0.         0.95099005 0.95099005]\n",
            " [0.95099005 0.96059601 0.         0.94148015]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.         0.9801     0.         0.96059601]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.96059601 0.         0.970299   0.95099005]\n",
            " [0.96059601 0.9801     0.9801     0.        ]\n",
            " [0.970299   0.99       0.         0.970299  ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.         0.9801     0.99       0.970299  ]\n",
            " [0.9801     0.99       1.         0.9801    ]\n",
            " [0.         0.         0.         0.        ]]\n",
            "Total setup training episode 15000\n",
            "Total optimal training episode 14726\n"
          ]
        }
      ],
      "source": [
        "# Traning the agent\n",
        "rewards = []\n",
        "lst_qtables = []\n",
        "num_optimal_episode = 0\n",
        "\n",
        "for episode in range(total_episodes):\n",
        "    state = env.reset()\n",
        "    step = 0\n",
        "    done = False\n",
        "    total_rewards = 0\n",
        "    for step in range(max_steps):\n",
        "\n",
        "        if random.uniform(0,1) > epsilon:\n",
        "            action = np.argmax(qtable[state,:]) # Exploit\n",
        "        else:\n",
        "            # This is same thing as np.random.choice(action)\n",
        "            action = env.action_space.sample() # Explore\n",
        "\n",
        "        # terminated is a step that reach to a positive or negative done state.\n",
        "        # truncated is a step that reach to out of bounds or strategy or rules.\n",
        "        new_state, reward, terminated, truncated, info = env.step(action)\n",
        "        done = terminated or truncated\n",
        "\n",
        "        max_new_state = np.max(qtable[new_state,:])\n",
        "\n",
        "        qtable[state,action] = qtable[state,action] + learning_rate*(reward+gamma*max_new_state-qtable[state,action])\n",
        "        lst_qtables.append(qtable[state,action])\n",
        "        total_rewards += reward\n",
        "\n",
        "        state = new_state\n",
        "        if done:\n",
        "            break\n",
        "\n",
        "    num_optimal_episode += 1\n",
        "    epsilon = min_epsilon + (max_epsilon - min_epsilon)*np.exp(-decay_rate*episode)\n",
        "    rewards.append(total_rewards)\n",
        "\n",
        "    # Check converge  of q-table when equal to required score\n",
        "    if  sum(rewards)/total_episodes > 0.9:\n",
        "      if converged_qtable(lst_qtables):\n",
        "        break\n",
        "\n",
        "# Max score = 1 or 100%\n",
        "print(\"Score:\", str(sum(rewards)/total_episodes))\n",
        "print(f\"lasted update of qtable: \\n{qtable}\")\n",
        "print(f\"Total setup training episode {total_episodes}\")\n",
        "print(f\"Total optimal training episode {num_optimal_episode}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "anegXT4kZFxf",
        "outputId": "215c9ad9-3130-4973-a1c6-7fc8883b9ad8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode: 1\n",
            "['\\n\\x1b[41mS\\x1b[0mFFF\\nFHFH\\nFFFH\\nHFFG\\n', '  (Down)\\nSFFF\\n\\x1b[41mF\\x1b[0mHFH\\nFFFH\\nHFFG\\n', '  (Down)\\nSFFF\\nFHFH\\n\\x1b[41mF\\x1b[0mFFH\\nHFFG\\n', '  (Right)\\nSFFF\\nFHFH\\nF\\x1b[41mF\\x1b[0mFH\\nHFFG\\n', '  (Down)\\nSFFF\\nFHFH\\nFFFH\\nH\\x1b[41mF\\x1b[0mFG\\n', '  (Right)\\nSFFF\\nFHFH\\nFFFH\\nHF\\x1b[41mF\\x1b[0mG\\n', '  (Right)\\nSFFF\\nFHFH\\nFFFH\\nHFF\\x1b[41mG\\x1b[0m\\n']\n",
            "Number of Steps: 5\n",
            "Episode: 2\n",
            "['\\n\\x1b[41mS\\x1b[0mFFF\\nFHFH\\nFFFH\\nHFFG\\n', '  (Down)\\nSFFF\\n\\x1b[41mF\\x1b[0mHFH\\nFFFH\\nHFFG\\n', '  (Down)\\nSFFF\\nFHFH\\n\\x1b[41mF\\x1b[0mFFH\\nHFFG\\n', '  (Right)\\nSFFF\\nFHFH\\nF\\x1b[41mF\\x1b[0mFH\\nHFFG\\n', '  (Down)\\nSFFF\\nFHFH\\nFFFH\\nH\\x1b[41mF\\x1b[0mFG\\n', '  (Right)\\nSFFF\\nFHFH\\nFFFH\\nHF\\x1b[41mF\\x1b[0mG\\n', '  (Right)\\nSFFF\\nFHFH\\nFFFH\\nHFF\\x1b[41mG\\x1b[0m\\n']\n",
            "Number of Steps: 5\n",
            "Episode: 3\n",
            "['\\n\\x1b[41mS\\x1b[0mFFF\\nFHFH\\nFFFH\\nHFFG\\n', '  (Down)\\nSFFF\\n\\x1b[41mF\\x1b[0mHFH\\nFFFH\\nHFFG\\n', '  (Down)\\nSFFF\\nFHFH\\n\\x1b[41mF\\x1b[0mFFH\\nHFFG\\n', '  (Right)\\nSFFF\\nFHFH\\nF\\x1b[41mF\\x1b[0mFH\\nHFFG\\n', '  (Down)\\nSFFF\\nFHFH\\nFFFH\\nH\\x1b[41mF\\x1b[0mFG\\n', '  (Right)\\nSFFF\\nFHFH\\nFFFH\\nHF\\x1b[41mF\\x1b[0mG\\n', '  (Right)\\nSFFF\\nFHFH\\nFFFH\\nHFF\\x1b[41mG\\x1b[0m\\n']\n",
            "Number of Steps: 5\n",
            "Episode: 4\n",
            "['\\n\\x1b[41mS\\x1b[0mFFF\\nFHFH\\nFFFH\\nHFFG\\n', '  (Down)\\nSFFF\\n\\x1b[41mF\\x1b[0mHFH\\nFFFH\\nHFFG\\n', '  (Down)\\nSFFF\\nFHFH\\n\\x1b[41mF\\x1b[0mFFH\\nHFFG\\n', '  (Right)\\nSFFF\\nFHFH\\nF\\x1b[41mF\\x1b[0mFH\\nHFFG\\n', '  (Down)\\nSFFF\\nFHFH\\nFFFH\\nH\\x1b[41mF\\x1b[0mFG\\n', '  (Right)\\nSFFF\\nFHFH\\nFFFH\\nHF\\x1b[41mF\\x1b[0mG\\n', '  (Right)\\nSFFF\\nFHFH\\nFFFH\\nHFF\\x1b[41mG\\x1b[0m\\n']\n",
            "Number of Steps: 5\n",
            "Episode: 5\n",
            "['\\n\\x1b[41mS\\x1b[0mFFF\\nFHFH\\nFFFH\\nHFFG\\n', '  (Down)\\nSFFF\\n\\x1b[41mF\\x1b[0mHFH\\nFFFH\\nHFFG\\n', '  (Down)\\nSFFF\\nFHFH\\n\\x1b[41mF\\x1b[0mFFH\\nHFFG\\n', '  (Right)\\nSFFF\\nFHFH\\nF\\x1b[41mF\\x1b[0mFH\\nHFFG\\n', '  (Down)\\nSFFF\\nFHFH\\nFFFH\\nH\\x1b[41mF\\x1b[0mFG\\n', '  (Right)\\nSFFF\\nFHFH\\nFFFH\\nHF\\x1b[41mF\\x1b[0mG\\n', '  (Right)\\nSFFF\\nFHFH\\nFFFH\\nHFF\\x1b[41mG\\x1b[0m\\n']\n",
            "Number of Steps: 5\n",
            "Episode: 6\n",
            "['\\n\\x1b[41mS\\x1b[0mFFF\\nFHFH\\nFFFH\\nHFFG\\n', '  (Down)\\nSFFF\\n\\x1b[41mF\\x1b[0mHFH\\nFFFH\\nHFFG\\n', '  (Down)\\nSFFF\\nFHFH\\n\\x1b[41mF\\x1b[0mFFH\\nHFFG\\n', '  (Right)\\nSFFF\\nFHFH\\nF\\x1b[41mF\\x1b[0mFH\\nHFFG\\n', '  (Down)\\nSFFF\\nFHFH\\nFFFH\\nH\\x1b[41mF\\x1b[0mFG\\n', '  (Right)\\nSFFF\\nFHFH\\nFFFH\\nHF\\x1b[41mF\\x1b[0mG\\n', '  (Right)\\nSFFF\\nFHFH\\nFFFH\\nHFF\\x1b[41mG\\x1b[0m\\n']\n",
            "Number of Steps: 5\n",
            "Episode: 7\n",
            "['\\n\\x1b[41mS\\x1b[0mFFF\\nFHFH\\nFFFH\\nHFFG\\n', '  (Down)\\nSFFF\\n\\x1b[41mF\\x1b[0mHFH\\nFFFH\\nHFFG\\n', '  (Down)\\nSFFF\\nFHFH\\n\\x1b[41mF\\x1b[0mFFH\\nHFFG\\n', '  (Right)\\nSFFF\\nFHFH\\nF\\x1b[41mF\\x1b[0mFH\\nHFFG\\n', '  (Down)\\nSFFF\\nFHFH\\nFFFH\\nH\\x1b[41mF\\x1b[0mFG\\n', '  (Right)\\nSFFF\\nFHFH\\nFFFH\\nHF\\x1b[41mF\\x1b[0mG\\n', '  (Right)\\nSFFF\\nFHFH\\nFFFH\\nHFF\\x1b[41mG\\x1b[0m\\n']\n",
            "Number of Steps: 5\n",
            "Episode: 8\n",
            "['\\n\\x1b[41mS\\x1b[0mFFF\\nFHFH\\nFFFH\\nHFFG\\n', '  (Down)\\nSFFF\\n\\x1b[41mF\\x1b[0mHFH\\nFFFH\\nHFFG\\n', '  (Down)\\nSFFF\\nFHFH\\n\\x1b[41mF\\x1b[0mFFH\\nHFFG\\n', '  (Right)\\nSFFF\\nFHFH\\nF\\x1b[41mF\\x1b[0mFH\\nHFFG\\n', '  (Down)\\nSFFF\\nFHFH\\nFFFH\\nH\\x1b[41mF\\x1b[0mFG\\n', '  (Right)\\nSFFF\\nFHFH\\nFFFH\\nHF\\x1b[41mF\\x1b[0mG\\n', '  (Right)\\nSFFF\\nFHFH\\nFFFH\\nHFF\\x1b[41mG\\x1b[0m\\n']\n",
            "Number of Steps: 5\n",
            "Episode: 9\n",
            "['\\n\\x1b[41mS\\x1b[0mFFF\\nFHFH\\nFFFH\\nHFFG\\n', '  (Down)\\nSFFF\\n\\x1b[41mF\\x1b[0mHFH\\nFFFH\\nHFFG\\n', '  (Down)\\nSFFF\\nFHFH\\n\\x1b[41mF\\x1b[0mFFH\\nHFFG\\n', '  (Right)\\nSFFF\\nFHFH\\nF\\x1b[41mF\\x1b[0mFH\\nHFFG\\n', '  (Down)\\nSFFF\\nFHFH\\nFFFH\\nH\\x1b[41mF\\x1b[0mFG\\n', '  (Right)\\nSFFF\\nFHFH\\nFFFH\\nHF\\x1b[41mF\\x1b[0mG\\n', '  (Right)\\nSFFF\\nFHFH\\nFFFH\\nHFF\\x1b[41mG\\x1b[0m\\n']\n",
            "Number of Steps: 5\n",
            "Episode: 10\n",
            "['\\n\\x1b[41mS\\x1b[0mFFF\\nFHFH\\nFFFH\\nHFFG\\n', '  (Down)\\nSFFF\\n\\x1b[41mF\\x1b[0mHFH\\nFFFH\\nHFFG\\n', '  (Down)\\nSFFF\\nFHFH\\n\\x1b[41mF\\x1b[0mFFH\\nHFFG\\n', '  (Right)\\nSFFF\\nFHFH\\nF\\x1b[41mF\\x1b[0mFH\\nHFFG\\n', '  (Down)\\nSFFF\\nFHFH\\nFFFH\\nH\\x1b[41mF\\x1b[0mFG\\n', '  (Right)\\nSFFF\\nFHFH\\nFFFH\\nHF\\x1b[41mF\\x1b[0mG\\n', '  (Right)\\nSFFF\\nFHFH\\nFFFH\\nHFF\\x1b[41mG\\x1b[0m\\n']\n",
            "Number of Steps: 5\n"
          ]
        }
      ],
      "source": [
        "# Let's agent play n times\n",
        "env.reset()\n",
        "\n",
        "n = 10\n",
        "for episode in range(n):\n",
        "    state = env.reset()\n",
        "    step = 0\n",
        "    done = False\n",
        "\n",
        "    print(\"Episode:\", episode+1)\n",
        "\n",
        "    for step in range(max_steps):\n",
        "        action = np.argmax(qtable[state,:])\n",
        "        new_state, reward, terminated, truncated, info = env.step(action)\n",
        "        done = terminated or truncated\n",
        "\n",
        "        if done:\n",
        "            print(env.render())\n",
        "            print(\"Number of Steps:\", step)\n",
        "            break\n",
        "        state = new_state\n",
        "\n",
        "env.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "QTW5FUr-ZFxh"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}